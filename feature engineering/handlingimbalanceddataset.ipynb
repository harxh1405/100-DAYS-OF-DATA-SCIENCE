{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5ed231",
   "metadata": {},
   "source": [
    "##Handling imbalanced dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb80cd",
   "metadata": {},
   "source": [
    "Consider classification problem where we have a datset(1000 data points) and output is a category(yes/no\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e15d8",
   "metadata": {},
   "source": [
    "Suppose we have 900 yes and 100 no data points (9:1)\n",
    "===> Imbalance in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08c61b",
   "metadata": {},
   "source": [
    "Our model will get biased to the maximum number of data points(yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c0a4b",
   "metadata": {},
   "source": [
    "Two techniques -> Up sampling and Down sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5466586",
   "metadata": {},
   "source": [
    "In up sampling we increase the minority and in down sampling we decrease the majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b29764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "n_sample = 1000\n",
    "class_0_ratio = 0.9 ##90 percent class ratio\n",
    "n_class_0 = int(n_sample * class_0_ratio)\n",
    "n_class_1 = n_sample - n_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803ae541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class_0, n_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea7f48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREATE DATAFRAME WITH IMBALANCED DATASET\n",
    "class_0 = pd.DataFrame({\n",
    "    \"feature_1\": np.random.normal(loc=2, scale=1, size=n_class_0),\n",
    "    \"feature_2\": np.random.normal(loc=2, scale=1, size=n_class_0),\n",
    "    \"target\": [0]*n_class_0\n",
    "})\n",
    "class_1 = pd.DataFrame({\n",
    "    \"feature_1\": np.random.normal(loc=2, scale=1, size=n_class_1),\n",
    "    \"feature_2\": np.random.normal(loc=2, scale=1, size=n_class_1),\n",
    "    \"target\": [1]*n_class_1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4f652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([class_0, class_1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89241612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.225776</td>\n",
       "      <td>2.285744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798623</td>\n",
       "      <td>2.333279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.096257</td>\n",
       "      <td>2.531807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.861037</td>\n",
       "      <td>1.645234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.479633</td>\n",
       "      <td>0.879185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  target\n",
       "0   0.225776   2.285744       0\n",
       "1   0.798623   2.333279       0\n",
       "2   3.096257   2.531807       0\n",
       "3   2.861037   1.645234       0\n",
       "4   0.479633   0.879185       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b45c0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9240e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Up Sampling\n",
    "df_minority = df[df['target']==1]\n",
    "df_majority = df[df['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be119600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit_learn in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from scikit_learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from scikit_learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from scikit_learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from scikit_learn) (3.6.0)\n",
      "Collecting sklearn.utils\n",
      "  Downloading sklearn_utils-0.0.15.tar.gz (26 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from sklearn.utils) (2.3.4)\n",
      "Collecting pyfunctional (from sklearn.utils)\n",
      "  Downloading pyfunctional-1.5.0-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from sklearn.utils) (2.3.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from sklearn.utils) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from sklearn.utils) (1.7.2)\n",
      "Collecting statsmodels (from sklearn.utils)\n",
      "  Downloading statsmodels-0.14.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from sklearn.utils) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from pandas->sklearn.utils) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from pandas->sklearn.utils) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from pandas->sklearn.utils) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->sklearn.utils) (1.17.0)\n",
      "Collecting dill>=0.2.5 (from pyfunctional->sklearn.utils)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tabulate<=1.0.0 (from pyfunctional->sklearn.utils)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from scikit-learn->sklearn.utils) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from scikit-learn->sklearn.utils) (3.6.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from seaborn->sklearn.utils) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->sklearn.utils) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->sklearn.utils) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->sklearn.utils) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->sklearn.utils) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->sklearn.utils) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->sklearn.utils) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->sklearn.utils) (3.2.5)\n",
      "Collecting patsy>=0.5.6 (from statsmodels->sklearn.utils)\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pyfunctional-1.5.0-py3-none-any.whl (53 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading statsmodels-0.14.5-cp312-cp312-macosx_11_0_arm64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m742.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Building wheels for collected packages: sklearn.utils\n",
      "\u001b[33m  DEPRECATION: Building 'sklearn.utils' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sklearn.utils'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for sklearn.utils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn.utils: filename=sklearn_utils-0.0.15-py3-none-any.whl size=27942 sha256=7c99886eb1a37a25f3da4b7637bf78fd0de082cbe8bd275814e2362d15d36639\n",
      "  Stored in directory: /Users/harshsingh/Library/Caches/pip/wheels/ed/ed/51/21a8cdae39ae51a93bcb2d2f092e5cf722255d42147df1e4bf\n",
      "Successfully built sklearn.utils\n",
      "Installing collected packages: tabulate, patsy, dill, pyfunctional, statsmodels, sklearn.utils\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [sklearn.utils]0m [statsmodels]\n",
      "\u001b[1A\u001b[2KSuccessfully installed dill-0.4.0 patsy-1.0.2 pyfunctional-1.5.0 sklearn.utils-0.0.15 statsmodels-0.14.5 tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit_learn\n",
    "!pip install sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f829e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "##extrapolation\n",
    "##we will now upsample the minority dataset\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c871568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_minority_upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c312324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb479fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a718a5",
   "metadata": {},
   "source": [
    "##Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e529da3d",
   "metadata": {},
   "source": [
    "often considered bad because we are losing the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23937299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "n_sample = 1000\n",
    "class_0_ratio = 0.9 ##90 percent class ratio\n",
    "n_class_0 = int(n_sample * class_0_ratio)\n",
    "n_class_1 = n_sample - n_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60274faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##CREATE DATAFRAME WITH IMBALANCED DATASET\n",
    "class_0 = pd.DataFrame({\n",
    "    \"feature_1\": np.random.normal(loc=2, scale=1, size=n_class_0),\n",
    "    \"feature_2\": np.random.normal(loc=2, scale=1, size=n_class_0),\n",
    "    \"target\": [0]*n_class_0\n",
    "})\n",
    "class_1 = pd.DataFrame({\n",
    "    \"feature_1\": np.random.normal(loc=2, scale=1, size=n_class_1),\n",
    "    \"feature_2\": np.random.normal(loc=2, scale=1, size=n_class_1),\n",
    "    \"target\": [1]*n_class_1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd5597a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([class_0, class_1]).reset_index(drop=True)\n",
    "df.head()\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2600b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DOWN SAMPLING\n",
    "df_minority = df[df['target']==1]\n",
    "df_majority = df[df['target']==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea0fe836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "##extrapolation\n",
    "##we will now upsample the minority dataset\n",
    "df_majority_downsampled = resample(df_majority, n_samples=len(df_minority), random_state=42)\n",
    "\n",
    "df_majority_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e8dded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled = pd.concat([df_minority, df_majority_downsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff39369e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    100\n",
       "0    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled['target'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "campusx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
